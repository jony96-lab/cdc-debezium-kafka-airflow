## üèóÔ∏è Arquitectura del Proyecto
<p align="center">
  <img src="img/arquitectura.png" width="800" title="Arquitectura CDC">
</p>

## üìà Monitoreo y Observabilidad
<p align="center">
  <img src="img/airflow-dags.png" width="800" title="Airflow Dashboard">
</p>



Real-Time CDC Pipeline
Este proyecto implementa una arquitectura de Change Data Capture (CDC) de nivel industrial para replicar datos en tiempo real desde un sistema transaccional (MySQL) hacia un Data Warehouse (Postgres), garantizando la integridad y salud del pipeline mediante Apache Airflow 3.1.1.

üöÄ Vista General de la Soluci√≥n
El sistema resuelve el problema de la latencia en la toma de decisiones, transformando un Punto de Venta (POS) tradicional en una plataforma de datos orientada a eventos.

Ingesta: Captura de cambios basada en logs (Log-based CDC) con Debezium.

Mensajer√≠a: Streaming de eventos distribuido con Kafka (Modo KRaft).

Almacenamiento: Sincronizaci√≥n autom√°tica con JDBC Sink Connector hacia Postgres.

Orquestaci√≥n y Observabilidad: Monitoreo proactivo con Airflow 3, utilizando Dynamic Task Mapping para escalar el monitoreo de tablas e integridad.

üõ†Ô∏è Stack Tecnol√≥gico
Core: Docker & Docker Compose.

Data Streaming: Kafka 7.6 (Confluent), Debezium 2.5.

Orquestador: Apache Airflow 3.1.1 (Latest).

Bases de Datos: MySQL (Origen) y PostgreSQL (Destino).

üìä Arquitectura de Monitoreo (Airflow)
La pieza clave es la capa de observabilidad. He desarrollado DAGs din√°micos que aseguran la confiabilidad del dato:

Connector Health Monitor: Chequea la API de Kafka Connect cada 5 minutos. Si un conector pasa a estado FAILED, se dispara una alerta inmediata.

Data Integrity Check: Realiza validaciones cruzadas (COUNT(*)) entre origen y destino para detectar desfasajes en la replicaci√≥n.

Alerting System: Integraci√≥n con SMTP (Gmail) para notificaciones cr√≠ticas de fallos en el pipeline.

‚öôÔ∏è Configuraci√≥n del Pipeline
1. Conector de Origen (Debezium MySql)
Configurado para capturar todos los cambios del esquema pos_bi_db. El uso de table.include.list permite un escalado controlado de las entidades a replicar.

JSON
{
  "name": "mysql-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.include.list": "pos_bi_db",
    "topic.prefix": "mysql-server",
    "schema.history.internal.kafka.bootstrap.servers": "kafka:29092"
  }
}
2. Conector de Destino (JDBC Sink)
Implementa Upsert logic y Automatic Schema Evolution, lo que permite que el Data Warehouse se adapte a cambios menores en el origen sin intervenci√≥n manual.

üìù Gu√≠a de Operaci√≥n (Escalabilidad)
Para agregar una nueva tabla al monitoreo e integridad:

Postgres: Crear la tabla espejo en el destino.

Connectors: Actualizar la lista de tablas en los archivos JSON de configuraci√≥n.

Airflow UI: Simplemente actualizar la variable CDC_MONITORED_TABLES desde la interfaz de Airflow. No requiere reinicio de servicios.